{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_영화리뷰_감성분석_1024(오후3).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO38qaDgRbyQ3onIFFG0oPx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kibbm/ML-Tensorflow/blob/master/LSTM_%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0_%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D_1024(%EC%98%A4%ED%9B%843).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFJz3Ab8PBDo"
      },
      "source": [
        "*신경망 교과서 /* \n",
        "## 6장 **LSTM을 사용한 영화 리뷰 감성 분석**\n",
        "\n",
        "https://github.com/PacktPublishing/Neural-Network-Projects-with-Python/blob/master/Chapter06/lstm.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qcV0Ev9TgNr"
      },
      "source": [
        "6.6 IMDB영화 리뷰 데이터 셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmZ_mAUI_Hz7",
        "outputId": "403d7307-b92d-4cd9-9c8c-03bbbb255b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import matplotlib\n",
        "#matplotlib.use(\"TkAgg\")\n",
        "\n",
        "from keras.datasets import imdb\n",
        "training_set, testing_set = imdb.load_data(index_from = 3)\n",
        "X_train, y_train = training_set\n",
        "X_test, y_test = testing_set\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fr5ys4yQ_XV"
      },
      "source": [
        "단어가 아닌 숫자가 나온 이유는 단어를 숫자로 이미 인코딩했기 때문이다. \n",
        "케라스에 내장된 딕셔너리를 사용해 단어로 다시 변환할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VxsC_WJRVv1",
        "outputId": "85ec25b0-f570-4805-ace0-c8929f09fdd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {key:(value+3) for key, value in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "id_to_word = {value:key for key, value in word_to_id.items()}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYEE_v_VR4WM"
      },
      "source": [
        "이제 실제 리뷰를 출력할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JywMyo8pR2m1",
        "outputId": "f9874da1-6d24-4471-d03e-4b258daa8474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(' '.join(id_to_word[id] for id in X_train[159]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> a rating of 1 does not begin to express how dull depressing and relentlessly bad this movie is\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwSwSwr1SfLj"
      },
      "source": [
        "159번.. 분명 이 리뷰의 감성은 부정적이다. y값을 출력해 확인하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5haeoG7YSkGj",
        "outputId": "5e0d6fea-edf5-46e8-c293-a5f7b9f4227b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(y_train[159])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arH7B97ESwqj"
      },
      "source": [
        "값이 0이면 부정, 1이면 긍정리뷰임. \n",
        "긍정리뷰도 출력해보자.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0ikQYeiTA6k",
        "outputId": "98fb7b4e-f08c-47da-c0de-4d1867106094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(' '.join(id_to_word[id] for id in X_train[6]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> lavish production values and solid performances in this straightforward adaption of jane austen's satirical classic about the marriage game within and between the classes in provincial 18th century england northam and paltrow are a salutory mixture as friends who must pass through jealousies and lies to discover that they love each other good humor is a sustaining virtue which goes a long way towards explaining the accessability of the aged source material which has been toned down a bit in its harsh scepticism i liked the look of the film and how shots were set up and i thought it didn't rely too much on successions of head shots like most other films of the 80s and 90s do very good results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sf952ItTNEz",
        "outputId": "497b86dd-9b9a-4b3e-ba05-885664a00dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(y_train[6])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucu6zCOWTju7"
      },
      "source": [
        "6.7 단어의 벡터 표현\n",
        "\n",
        " cf) CNN: 입력데이터인 이미지는 기본적으로 3차원 벡터(즉, 행렬) 형태이며, 각 차원은 이미지의 가로, 세로, 채널수를 의미한다. 벡터 값은 각 화소의 강도를 나타낸다.\n",
        "\n",
        "* 6.7.1 원핫 인코딩\n",
        ": **단어**는 이미지와 다르게 **숫자로 변환해야** 한다. \n",
        "* 6.7.2 단어 임베딩\n",
        ": 단어를 더 나은 형태의 벡터로 표현하는 방법을 학습하는 기법. 단어 임베딩으로 만든 벡터가 원핫 인코딩보다 더 나은 이유는 **벡터 차원이 더 작고 유사한 단어들이 서로 가깝게 놓이기 때문**. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7RdAQlZVWnq"
      },
      "source": [
        "6.8 모델 아키텍처\n",
        "\n",
        "     입력  --->    단어   -->    LSTM 레이어    --> 밀집 레이어     --> 출력\n",
        "   (영화 리뷰)  임베딩 레이어              시그모이드 함수 사용    (리뷰의 감성)\n",
        "\n",
        "   6.6절에서 살펴봤듯이 케라스에 내장된 IMDB 영화 리뷰 데이터셋에는 영단어가 이미 숫자로 인코딩 됐다. 하지만 아직 한가지 문제가 남아있다. 영화리뷰, 즉 영어 문장은 길이가 제각각 다르다. 각 리뷰를 단순히 벡터로 만들면 벤터 길이 또한 각각 다르며, 신경망은 길이가 다른 벡터를 입력받을 수 없다.(해결방법은 6.9절에서)\n",
        "\n",
        "*   6.8.1 입력\n",
        "*   6.8.2 단어 임베딩 레이어\n",
        "*   6.8.3 LSTM레이어\n",
        "*   6.8.4 밀집 레이어\n",
        "*   6.8.5 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSMVaSRaWoEk"
      },
      "source": [
        "6.9 모델 구성\n",
        "\n",
        "\n",
        "*   6.9.1 데이터 입수\n",
        "*   6.9.2 제로 패딩: 영화 리뷰의 길이를 maxlen매개변수로 정의해 이 문제를 해결해보자. maxlen보다 긴 리뷰는 자르고 maxlen보다 짧은 리뷰에는 0을 채울 수 있다. 이 과정을 제로 패딩(zero padding)이라고 하며, 모든 입력 벡터를 동일한 길이로 맞춰준다. \n",
        "*   6.9.3 단어 임베딩 레이어와 LSTM 레이어: 전처리한 다음에는 모델을 만들어야 한다. \n",
        "*   6.9.4 모델 컴파일 및 훈련: 컴파일하려면 매개변수(손실함수, 옵티마이저)를 지정해야 한다. \n",
        "       - 손실함수) 목표변수가 이진변수라면, binary_crossentropy | 다중 클래스를 출력한다면, categoricla_crossentropy\n",
        "       - 옵티마이저) 데이터셋에 따라 옵티마이저 성능이 달라지며, 경사 소실 문제와 경사 폭증 문제 때문에 특정 옵티마이저가 데이터셋을 제대로 학습하지 못하는 경우도 있음. 예>sgd, RMSprop, adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GtBGMy1VHkt",
        "outputId": "99e3eb72-8b93-4862-ee45-c337e17712b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 6.9.1 데이터 입수\n",
        "from keras.datasets import imdb\n",
        "\n",
        "training_set, testing_set = imdb.load_data(num_words = 10000)\n",
        "X_train, y_train = training_set\n",
        "X_test, y_test = testing_set\n",
        "\n",
        "print(\"Number of training samples = {}\".format(X_train.shape[0]))\n",
        "print(\"Number of testing samples = {}\".format(X_test.shape[0]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples = 25000\n",
            "Number of testing samples = 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PbqotIFYf9T"
      },
      "source": [
        "훈련 데이터셋과 테스트 데이터셋에 각각 25,000 개의 로우가 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XhgGBU8T7wk",
        "outputId": "c1ac1978-3fd7-4ec7-8c2d-7f311cb8d58b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 6.9.2 제로 패딩\n",
        "'''\n",
        "제로피딩은 케랄스의 preprocessing모둘에 있는 sequence클래스를 사용해 손쉽게 적용할 수 있다. \n",
        "- sequence클래스는 이 밖에도 시퀀스 데이터를 다루는 여러 유용한 기능을 제공한다.\n",
        "- maxlen을 100으로 지정하고 훈련 데이터셋과 테스트 데이터셋을 함수에 전달한다. \n",
        "훈련데이터셋과 테스트 데이터셋은 각각 25,000개의 로우가 있다. \n",
        "'''\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "X_train_padded = sequence.pad_sequences(X_train, maxlen = 100) #시퀀스 데이터에 제로패딩 적용\n",
        "X_test_padded = sequence.pad_sequences(X_test, maxlen = 100)\n",
        "\n",
        "print(\"X_train vector shape = {}\".format(X_train_padded.shape)) #벡터길이 출력해 제로 패딩 결과 보기.\n",
        "print(\"X_test vector shape = {}\".format(X_test_padded.shape))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train vector shape = (25000, 100)\n",
            "X_test vector shape = (25000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J00JGt6vZpDJ",
        "outputId": "3bae29b1-7dda-44dc-e058-44d9ce976e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#   6.9.3 단어 임베딩 레이어와 LSTM 레이어\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim = 10000, output_dim=128)) #입력벡터 차원을 지정(입력 벡터의 차원 수는 데이터셋이 있는 \n",
        "                              #단어의 고유 개수와 동일해야 함.따라서, 앞서 데이터 셋을 가져올 때 지정했던 num_words매개 변수 값을 그대로 사용한다.)\n",
        "                              #출력 벡터 차원을 128로 지정한다. \n",
        "model.add(LSTM(units=128)) #레이어의 반복 유닛 수를 지정. LSTM레이어를 생성해 모델에 추가. \n",
        "model.add(Dense(units=1, activation='sigmoid')) #dense레이어를 추가하고 sigmoid를 활성화 함수로 지정한다. dense레이어의 역할은 모델 출력을 0과 1사이의 확률로 변환하는 것이다. \n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,411,713\n",
            "Trainable params: 1,411,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6bnHegeg0Gq",
        "outputId": "625c6432-647c-4201-97b0-737aa4655c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# 6.9.4 모델 컴파일 및 훈련\n",
        "\n",
        "#1> SGD옵티마이저\n",
        "Optimizer = 'SGD'\n",
        "model.compile(loss='binary_crossentropy', optimizer = Optimizer)\n",
        "\n",
        "#에폭 10, 테스트셋을 validation_data로 지정해 모델 훈련 \n",
        "scores = model.fit(x=X_train_padded, y=y_train, \n",
        "                  batch_size = 128, epochs=10, \n",
        "                  validation_data=(X_test_padded, y_test))\n",
        "#반환한 scores객체는 훈련 정확도, 검증 정확도, 에폭별 손실 값 등을 담은 파이썬 딕셔너리다. "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "196/196 [==============================] - 96s 490ms/step - loss: 0.6930 - val_loss: 0.6929\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 102s 521ms/step - loss: 0.6929 - val_loss: 0.6928\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 101s 516ms/step - loss: 0.6928 - val_loss: 0.6928\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 98s 501ms/step - loss: 0.6927 - val_loss: 0.6927\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 97s 496ms/step - loss: 0.6927 - val_loss: 0.6926\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 98s 499ms/step - loss: 0.6926 - val_loss: 0.6926\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 98s 502ms/step - loss: 0.6925 - val_loss: 0.6925\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 102s 521ms/step - loss: 0.6924 - val_loss: 0.6924\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 99s 503ms/step - loss: 0.6923 - val_loss: 0.6923\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 98s 499ms/step - loss: 0.6923 - val_loss: 0.6923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE8OYMQFl2v5"
      },
      "source": [
        "# 옵티마이저 별로 함수 만들기....optimizer를 인수로 받는 train_model()함수를 정의할 수 있다. \n",
        "\n",
        "def train_model(Optimizer, X_train, y_train, X_val, y_val):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim = 10000, output_dim=128))\n",
        "  model.add(LSTM(units=128))\n",
        "  model.add(Dense(units=1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer = Optimizer, metrics=['accuracy'])\n",
        "  scores = model.fit(X_train, y_train, batch_size=128, \n",
        "                     epochs=10, \n",
        "                     validation_data=(X_val, y_val),\n",
        "                     verbose=0)\n",
        "  return scores, model\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCJC8LXnnG7o"
      },
      "source": [
        "# 이 함수에 sgd, RMSprop, adam 옵티마이저를 각각 전달해 세가지 모델을 만든다.\n",
        "\n",
        "sgd_score, SGD_model = train_model(Optimizer = 'sgd', \n",
        "                                   X_train = X_train_padded,\n",
        "                                   y_train = y_train,\n",
        "                                   X_val = X_test_padded,\n",
        "                                   y_val = y_test)\n",
        "\n",
        "RMSprop_score, RMSprop_model = train_model(Optimizer = 'RMSprop', \n",
        "                                   X_train = X_train_padded,\n",
        "                                   y_train = y_train,\n",
        "                                   X_val = X_test_padded,\n",
        "                                   y_val = y_test)\n",
        "\n",
        "Adam_score, Adam_model = train_model(Optimizer = 'adam', \n",
        "                                   X_train = X_train_padded,\n",
        "                                   y_train = y_train,\n",
        "                                   X_val = X_test_padded,\n",
        "                                   y_val = y_test)                                   "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfp5ky53mQno"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9v8XBu6n52P"
      },
      "source": [
        "6.10 결과 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVbKVYdpn8xe",
        "outputId": "29c91b76-f9d3-4612-f65a-b826c4e31b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(range(1, 11), sgd_score.history['acc'], label='Training Accuracy')              # 오류................KeyError: 'acc'\n",
        "plt.plot(range(1, 11), sgd_score.history['val_acc'], label='Validation Accuracy')\n",
        "plt.axis([1, 10, 0, 1, 0])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Validation Accuracy using SGD Optimizer')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#훈련 정확도와 검증 정확도가 50%에서 멈췄다.ㅠㅠ"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-26c20d47f3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFF5kKyWszrA",
        "outputId": "4e6cf37f-b572-4cab-ff43-f17b191a2f1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "plt.plot(range(1,11), RMSprop_score.history['acc'], label='Training Accuracy')  \n",
        "plt.plot(range(1,11), RMSprop_score.history['val_acc'], label='Validation Accuracy')\n",
        "plt.axis([1, 10, 0, 1, 0])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Validation Accuracy using RMSprop Optimizer')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#RMSprop의 결과가 훨씬 낫다..에폭 10회만으로도 95%이상의 훈련 정확도와 85%의 검증 정확도를 얻었다. "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-0d87e9e76fa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSprop_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSprop_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train and Validation Accuracy using RMSprop Optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5rRq1-tMeu"
      },
      "source": [
        "plt.plot(range(1, 11), Adam_score.history['acc'], label='Training Accuracy')\n",
        "plt.plot(range(1, 11), Adam_score.history['val_acc'], label='Validation Accuracy')\n",
        "plt.axis([1, 10, 0, 1, 0])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Validation Accuracy using Adam Optimizer')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# adam옵티마이저 결과도 나쁘지 않다. 에폭 10회에서 훈련 정확도가 거의 100%에 가깝다. \n",
        "#  반면 검증 정확도는 약 80%로 나왔다. 이는 adam 옵티마이저가 과적합을 유발할 가능성이 있다는 뜻이다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkT8D-lkuL1B"
      },
      "source": [
        "반면 RMSprop옵티마이저는 훈련 정확도와 검증  정확도 간 차이가 더 작다. 따라서 예제 데이터셋에는 RMSprop옵티마이저를 사용한 LSTM신경망이 가장 적합하다고 결론 내릴 수 있다. 이제 RMSprop을 사용한 모델로 정확도를 더 분석해보자~~ => **혼돈행렬**\n",
        "\n",
        "\n",
        "\n",
        "*   진음성: 실제 클래스가 음성(부정적 리뷰)이고 모델도 음성으로 예측한 경우\n",
        "*   위양성: 실제 클래스가 음성(부정적 리뷰)이고 모델도 양성으로 예측한 경우\n",
        "*   위음성: 실제 클래스가 양성(긍정적 리뷰)이고 모델도 음성으로 예측한 경우\n",
        "*   진양성: 실제 클래스가 양성(긍정적 리뷰)이고 모델도 양성으로 예측한 경우\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg-J-PVHukxc"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.set(font_scale=2)\n",
        "y_test_pred = RMSprop_model.predict_classes(X_test_padded)\n",
        "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "ax = sns.heatmap(c_matrix, annot=True, xticklabels=['Negative Sentiment', 'Positive Sentiment'],\n",
        "                                      yticklabels=['Negative Sentiment', 'Positive Sentiment'],\n",
        "                 cbar=False, cmap='Blues', fmt='g')\n",
        "ax.set_xlabel(\"Prediction\")\n",
        "ax.set_ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juvhYjUGxm3l"
      },
      "source": [
        "모델이 테스트 데이터셋을 대부분 정확하게 분류했다. 진음성과 진양성이 전체의 85%정도를 차지했다. 즉, 영화 리뷰의 감성을 85% 정확도로 분류할 수 있다는 뜻이다. \n",
        "\n",
        "모델이 잘못 분류한 결과를 일부 골라 살펴보자. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8vauMOEx4oz"
      },
      "source": [
        "# 모델이 잘못 분류한 결과를 일부 골라 살펴보자. \n",
        "false_negatives = []\n",
        "false_positivies = []\n",
        "\n",
        "for i in range(len(y_test_pred)):\n",
        "  if y_test_pred[i][0] != y_test[i]:\n",
        "    if y+test[i] == 0: #위양성\n",
        "      false_positives.append(i)\n",
        "    else:\n",
        "      false_negatives.append(i)\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}